{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split in Train-, Valid- and Testdataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Attention:</b> The following variables must be edited.\n",
    "\n",
    "- __whitelistPath__ specifies which classes are to be considered.\n",
    "- __tsvFile__ contains metadata of all images, stored in a tsv file.\n",
    "\n",
    "\n",
    "- __tsvFileTrain__ is a tsv file in which the metadata for all training images is saved at the end.\n",
    "- __tsvFileValid__ is a tsv file in which the metadata for all validation images is saved at the end.\n",
    "- __tsvFileTest__ is a tsv file in which the metadata for all test images is saved at the end.\n",
    "\n",
    "\n",
    "- __trainPercentage__ specifies the percentage of total samples to be used as training data set.\n",
    "- __validPercentage__ specifies the percentage of total samples to be used as validation data set.\n",
    "- __testPercentage__ specifies the percentage of total samples to be used as test data set.\n",
    "\n",
    "\n",
    "- __randomSeed__ xy specifies a random seed value that is used through the entire notebook. This is necessary for reproducibility.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the root folder containing the training data.\n",
    "# If you want to have access to the data please contact ...\n",
    "basePath = ''\n",
    "\n",
    "whitelistPath = basePath + 'whitelist.txt'\n",
    "tsvFile =       basePath + 'Trainingsdatensatz_Klassengroesse.tsv'\n",
    "tsvFileTrain =  basePath + 'train.tsv'\n",
    "tsvFileValid =  basePath + 'val.tsv'\n",
    "tsvFileTest  =  basePath + 'test.tsv'\n",
    "\n",
    "trainPercentage = 60\n",
    "validPercentage = 20\n",
    "testPercentage  = 20\n",
    "\n",
    "randomSeed = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read whitelist\n",
    "\n",
    "whitelist = []\n",
    "\n",
    "with open(whitelistPath, errors='ignore') as whitelistfile:\n",
    "    reader = csv.reader(whitelistfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        whitelist.append(str(row)[2:-2])\n",
    "        \n",
    "len(whitelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tsv\n",
    "\n",
    "tsv = []\n",
    "udialect=csv.unix_dialect\n",
    "\n",
    "with open(tsvFile, dialect=udialect, errors='ignore') as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        tsv.append(row)\n",
    "len(tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(percent, whole):\n",
    "    return percent/100*whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method randomly divides samples in train, validation, and test datase for classes that have been augmented.The original samples are randomly split at first. The augmented samples were then added to the corresponding of the three data sets containing the original sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitAugmentedClass(classList):\n",
    "    print(\"Enter splitAugmentedClass...\")\n",
    "\n",
    "    origTrain = []\n",
    "    origValid = []\n",
    "    origTest  = []\n",
    "    \n",
    "    tempTrain = []\n",
    "    tempValid = []\n",
    "    tempTest  = []\n",
    "        \n",
    "    tempTrainNo = 0\n",
    "    tempValidNo = 0\n",
    "    tempTestNo  = 0\n",
    "    \n",
    "    origList = [] # Store all original rows (without \"augmentation\")\n",
    "    augmentedList = []\n",
    "    for row in classList:\n",
    "        if \"augmented\" not in row[0]:\n",
    "            origList.append(row)\n",
    "        if \"augmented\" in row[0]:\n",
    "            augmentedList.append(row)\n",
    "    \n",
    "    random.Random(randomSeed).shuffle(origList) \n",
    "    \n",
    "    trainNoOrig = int(percentage(trainPercentage, len(origList)))\n",
    "    validNoOrig = int(percentage(validPercentage, len(origList)))\n",
    "    testNoOrig  = int(percentage(testPercentage,  len(origList)))\n",
    "    \n",
    "    for i in range(trainNoOrig):\n",
    "           origTrain.append(origList.pop())\n",
    "    for i in range(validNoOrig):\n",
    "           origValid.append(origList.pop())\n",
    "    for i in range(testNoOrig):\n",
    "           origTest.append(origList.pop())\n",
    "            \n",
    "    \n",
    "    for origRow in origTrain:\n",
    "        for row in augmentedList:\n",
    "            if row[0].startswith(origRow[0]):\n",
    "                tempTrain.append(row)\n",
    "                \n",
    "    for origRow in origValid:\n",
    "        for row in augmentedList:\n",
    "            if row[0].startswith(origRow[0]):\n",
    "                tempValid.append(row)\n",
    "                \n",
    "    for origRow in origTest:\n",
    "        for row in augmentedList:\n",
    "            if row[0].startswith(origRow[0]):\n",
    "                tempTest.append(row)\n",
    "                \n",
    "    # Remaining Elements in origList                      \n",
    "    for origRow in origList:\n",
    "        for row in augmentedList:\n",
    "            if row[0].startswith(origRow[0]):\n",
    "                tempTrain.append(origRow)\n",
    "        tempTrain.append(origRow)\n",
    "    \n",
    "    tempTrain = tempTrain + origTrain\n",
    "    tempValid = tempValid + origValid\n",
    "    tempTest  = tempTest  + origTest\n",
    "    \n",
    "    return tempTrain, tempValid, tempTest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method randomly divides samples in train, validation, and test datase for classes that have not been augmented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitClass(classList):\n",
    "    print(\"Enter splitClass...\")\n",
    "    \n",
    "    trainNo = int(percentage(trainPercentage, len(classList)))\n",
    "    validNo = int(percentage(validPercentage, len(classList)))\n",
    "    testNo  = int(percentage(testPercentage,  len(classList)))\n",
    "\n",
    "    \n",
    "    random.Random(randomSeed).shuffle(classList)\n",
    "    \n",
    "    tr = []\n",
    "    va = []\n",
    "    te = []\n",
    "    \n",
    "    for i in range(trainNo):\n",
    "           tr.append(classList.pop())\n",
    "    for i in range(validNo):\n",
    "           va.append(classList.pop())\n",
    "    for i in range(testNo):\n",
    "           te.append(classList.pop())\n",
    "            \n",
    "    return tr, va, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [] # 60%\n",
    "valid = [] # 20%\n",
    "test  = [] # 20%\n",
    "udialect=csv.unix_dialect\n",
    "\n",
    "\n",
    "for planktonClass in whitelist:\n",
    "    classList = [] # Alle Tiere der aktuellen Klasse\n",
    "    augmented = False # handelt es sich bei dieser Klasse, um eine augmented Klasse?\n",
    "    for row in tsv:\n",
    "        if row[14].startswith(planktonClass):\n",
    "            classList.append(row)\n",
    "            if 'augmented' in row[0]:\n",
    "                augmented = True\n",
    "                \n",
    "    if augmented:\n",
    "        tr, va, te = splitAugmentedClass(classList)\n",
    "        train = train + tr\n",
    "        valid = valid + va\n",
    "        test  = test  + te\n",
    "    else:\n",
    "        tr, va, te = splitClass(classList)\n",
    "        train = train + tr\n",
    "        valid = valid + va\n",
    "        test  = test  + te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "print(len(valid))\n",
    "print(len(test))\n",
    "print(len(train +valid + test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tsvFileTrain, 'w') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, dialect=udialect, delimiter='\\t', quotechar=\"'\")\n",
    "    writer.writerows(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tsvFileValid, 'w') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, dialect=udialect, delimiter='\\t', quotechar=\"'\")\n",
    "    writer.writerows(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tsvFileTest, 'w') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, dialect=udialect, delimiter='\\t', quotechar=\"'\")\n",
    "    writer.writerows(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda-Python3.6]",
   "language": "python",
   "name": "conda-env-Anaconda-Python3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
