{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet - self-trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lsls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the root folder containing the training data.\n",
    "# If you want to have access to the data please contact ...\n",
    "basePath = ''\n",
    "\n",
    "imgDir    = basePath + 'images/Trainingsdatensatz_cropped_scaled/'\n",
    "trainTsv  = basePath + 'tsvDatein/final_dataset_splitting/train.tsv'\n",
    "validTsv  = basePath + 'tsvDatein/final_dataset_splitting/val.tsv'\n",
    "testTsv   = basePath + 'tsvDatein/final_dataset_splitting/test.tsv'\n",
    "whitelist = basePath + 'whitelist/whitelist1.txt'\n",
    "\n",
    "saveDir   = basePath + 'experiments/ResNet_selfTrained_101/'\n",
    "\n",
    "imgShape    = (1000,1000)\n",
    "num_classes = 11\n",
    "batch_size  = 1\n",
    "max_epochs  = 40\n",
    "preTrained  = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import csv\n",
    "from keras_applications.resnet import ResNet101, preprocess_input\n",
    "\n",
    "\n",
    "import keras\n",
    "import keras_applications\n",
    "keras_applications.set_keras_submodules(\n",
    "    backend=keras.backend,\n",
    "    layers=keras.layers,\n",
    "    models=keras.models,\n",
    "    utils=keras.utils\n",
    ")\n",
    "\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from contextlib import redirect_stdout\n",
    "import keras\n",
    "import pydot\n",
    "import pydotplus\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from IPython.display import SVG\n",
    "\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kopie aus der mgLearn Bibliothek. \n",
    "def heatmap(values, xlabel, ylabel, xticklabels, yticklabels, cmap=None,\n",
    "            vmin=None, vmax=None, ax=None, fmt=\"%0.2f\"):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    \n",
    "    # plot the mean cross-validation scores\n",
    "    img = ax.pcolor(values, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    img.update_scalarmappable()\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks(np.arange(len(xticklabels)) + 0.5)\n",
    "    ax.set_yticks(np.arange(len(yticklabels)) + 0.5)\n",
    "    ax.set_xticklabels(xticklabels, rotation='vertical')\n",
    "    ax.set_yticklabels(yticklabels)\n",
    "    ax.set_aspect(1)\n",
    "    \n",
    "    \n",
    "    for p, color, value in zip(img.get_paths(), img.get_facecolors(),\n",
    "                               img.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.mean(color[:3]) > 0.5:\n",
    "            c = 'k'\n",
    "        else:\n",
    "            c = 'w'\n",
    "        ax.text(x, y, fmt % value, color=c, ha=\"center\", va=\"center\", fontsize=12)\n",
    "    \n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/43186440\n",
    "\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "        path = saveDir + \"history/timeHistory.csv\"\n",
    "        with open(path,'a') as fd:\n",
    "            fd.write(str(time.time()-self.epoch_time_start) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTargetList(tsv, target_map):\n",
    "    \n",
    "    \n",
    "# Read target list.\n",
    "    with open(tsv) as f:\n",
    "        reader = csv.reader(f,delimiter='\\t')\n",
    "        target = []\n",
    "        imgId = []\n",
    "        next(reader)\n",
    "        i = 0\n",
    "        for class_name in reader:\n",
    "            if class_name[14] == \"\":\n",
    "                print(className)\n",
    "                continue\n",
    "\n",
    "            target.append([value for key, value in target_map.items() if key in class_name[14]]) # nur substring ist wichtig\n",
    "            imgId.append(class_name[0])\n",
    "            i = i+1\n",
    "            \n",
    "    return target, imgId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImgPaths(imgId):\n",
    "    filenames = (str(idx) + '.jpg' for idx in imgId)\n",
    "    return [imgDir + filename for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds(old_size, new_size):\n",
    "    if new_size >= old_size:\n",
    "        return (0, old_size)\n",
    "    else:\n",
    "        diff = old_size - new_size\n",
    "        low = diff // 2 + diff % 2\n",
    "        high = low + new_size\n",
    "        return (low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, shape):\n",
    "    left, right = bounds(img.shape[0], shape[0])\n",
    "    top, bottom = bounds(img.shape[1], shape[1])\n",
    "    img = img[left:right, top:bottom]\n",
    "    img = img[:, :,np.newaxis]\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence class for training using lazy batches of images.\n",
    "# See example at https://keras.io/utils/#sequence\n",
    "\n",
    "#\n",
    "# `X_set` is list of path to the images, and `y_set` are the associated classes.\n",
    "#\n",
    "class LokiImageSequence(Sequence):\n",
    "    def __init__(self, X_set, y_set, batch_size, image_shape):\n",
    "        self._X = list(X_set)\n",
    "        self._y = list(y_set)\n",
    "        self._batch_size = batch_size\n",
    "        self._image_shape = image_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self._X) / float(self._batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_X = self._X[idx * self._batch_size:(idx + 1) * self._batch_size]\n",
    "        batch_y = self._y[idx * self._batch_size:(idx + 1) * self._batch_size]\n",
    "        \n",
    "        x = []\n",
    "        for file_name in batch_X:\n",
    "            z = io.imread(file_name)\n",
    "            t = crop_image(z,self._image_shape)\n",
    "            d = t[:,:,0]\n",
    "            b = np.repeat(d[..., np.newaxis], 3, -1)\n",
    "            x.append(b)\n",
    "            \n",
    "        x = preprocess_input(np.array(x))\n",
    "        \n",
    "        return(np.array(x), np.array(batch_y, dtype=np.int8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datapreparation\n",
    "\n",
    "# tsv einlesen und Generator erstellen\n",
    "\n",
    "with open(whitelist) as f:\n",
    "    inverse_target_map = dict(enumerate(f))\n",
    "    target_map = {v[:-1]: k for (k, v) in inverse_target_map.items()}\n",
    "    num_classes=(1 + max(inverse_target_map))\n",
    "\n",
    "trainTarget, trainImgId = readTargetList(trainTsv, target_map)\n",
    "validTarget, validImgId = readTargetList(validTsv, target_map)\n",
    "testTarget,  testImgId  = readTargetList(testTsv,  target_map)\n",
    "    \n",
    "# shuffle\n",
    "combined = list(zip(trainTarget, trainImgId))\n",
    "random.shuffle(combined)\n",
    "trainTarget[:], trainImgId[:] = zip(*combined)\n",
    "\n",
    "# shuffle\n",
    "combined = list(zip(validTarget, validImgId))\n",
    "random.shuffle(combined)\n",
    "validTarget[:], validImgId[:] = zip(*combined)\n",
    "\n",
    "# shuffle\n",
    "combined = list(zip(testTarget, testImgId))\n",
    "random.shuffle(combined)\n",
    "testTarget[:], testImgId[:] = zip(*combined)\n",
    "\n",
    "        \n",
    "# Test anzahl an Bildern beschr√§nken\n",
    "#trainTarget = trainTarget[:10]\n",
    "#trainImgId = trainImgId[:10]\n",
    "#validTarget = validTarget[:10]\n",
    "#validImgId = validImgId[:10]\n",
    "#testTarget = testTarget[:10]\n",
    "#testImgId = testImgId[:10]\n",
    "\n",
    "\n",
    "# image file paths\n",
    "X_trainImgPath = getImgPaths(trainImgId)\n",
    "X_validImgPath = getImgPaths(validImgId)\n",
    "X_testImgPath  = getImgPaths(testImgId)\n",
    "\n",
    "# Convert class vectors to binary class matrices (format required by Keras).\n",
    "y_train = to_categorical(trainTarget, num_classes)\n",
    "y_valid = to_categorical(validTarget, num_classes)\n",
    "y_test  = to_categorical(testTarget,  num_classes)\n",
    "\n",
    "# Constructing sequences\n",
    "train_seq = LokiImageSequence(X_trainImgPath, y_train, batch_size, imgShape)\n",
    "valid_seq = LokiImageSequence(X_validImgPath, y_valid, batch_size, imgShape)\n",
    "test_seq  = LokiImageSequence(X_testImgPath,  y_test,  batch_size, imgShape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length trainingsset: \"  + str(len(y_train)))\n",
    "print(\"Length validationset: \" + str(len(y_valid)))\n",
    "print(\"Length testset: \"       + str(len(y_test)))\n",
    "print(\"Number of classes: \"    + str(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model customization\n",
    "\n",
    "if preTrained:\n",
    "    base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(1000,1000,3))\n",
    "else:\n",
    "    base_model = ResNet101(weights=None, include_top=False, input_shape=(1000,1000,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze all layers\n",
    "if preTrained:\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "# evtl. anpassen\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger_callback = CSVLogger(saveDir + \"history/model_history_log.csv\", append=True)\n",
    "checkpointEveryEpoch_callback = ModelCheckpoint(saveDir + \"modelFiles/saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\", monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "time_callback            = TimeHistory()\n",
    "earlyStopping_callback   = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, min_delta = 0.01)\n",
    "modelCheckpoint_callback = ModelCheckpoint(saveDir + 'modelFiles/best_model.h5', monitor='val_loss', verbose=1)\n",
    "\n",
    "callback_list = [time_callback, earlyStopping_callback, modelCheckpoint_callback, checkpointEveryEpoch_callback,csv_logger_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning\n",
    "history = model.fit_generator(train_seq,\n",
    "                     epochs = max_epochs,\n",
    "            validation_data = valid_seq,\n",
    "                  callbacks = callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern Model und weights\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(saveDir + \"modelFiles/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(saveDir + \"modelFiles/weights.h5\")\n",
    "\n",
    "\n",
    "# load a saved model\n",
    "model = load_model(saveDir + 'modelFiles/best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = saveDir + 'history/history.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.savefig(saveDir + 'history/accuracy.svg', transparent = True, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.savefig(saveDir + 'history/loss.svg', transparent = True, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.vis_utils.pydot = pydot\n",
    "plot_model(model, to_file=saveDir+'model_architecture_charts/model_small.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keras_model_verbose(model, show_shapes=True, show_layer_names=True):\n",
    "    return SVG(model_to_dot(model, show_shapes=show_shapes,         \n",
    "            show_layer_names=show_layer_names).create(prog='dot',format='svg'))\n",
    "\n",
    "\n",
    "svg = plot_keras_model_verbose(model, show_shapes=True, show_layer_names=False)\n",
    "\n",
    "with open(saveDir + \"model_architecture_charts/model_verbose.svg\", \"w\") as txt:\n",
    "    txt.write(svg.data)\n",
    "\n",
    "svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save mode summary\n",
    "with open(saveDir + 'model_architecture_charts/model_summary.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainings duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = time_callback.times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(times)\n",
    "df.to_csv (saveDir + r'trainingsDuration/durationPerEpoch.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = df.sum()\n",
    "sum.to_csv(saveDir + r'trainingsDuration/durationSum.csv') \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = df.mean()\n",
    "avg.to_csv(saveDir + r'trainingsDuration/durationAvgPerEpoch.csv') \n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predValid = model.predict_generator(valid_seq)\n",
    "predTest  = model.predict_generator(test_seq)\n",
    "\n",
    "loss, acc = model.evaluate_generator(test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validationset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueClassNum=[]\n",
    "for x in y_valid:\n",
    "    ind = np.array(x).argmax()\n",
    "    y = ind\n",
    "    trueClassNum.append(y)\n",
    "    \n",
    "    \n",
    "trueClassName = []\n",
    "for f in trueClassNum:\n",
    "     trueClassName.append(inverse_target_map[f][:-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predMultilabelAll=[]\n",
    "predProbabilityAll = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for x in predValid:\n",
    "    maxProb = x.max()\n",
    "    predProbabilityAll.append(maxProb)\n",
    "    \n",
    "    ind = x.argmax()\n",
    "    y = [0]*len(x)\n",
    "    y[ind]=1\n",
    "    predMultilabelAll.append(y)\n",
    "\n",
    "    counter +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to int\n",
    "predClassNum=[]\n",
    "for x in predMultilabelAll:\n",
    "    ind = np.array(x).argmax()\n",
    "    y = ind\n",
    "    predClassNum.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to name\n",
    "predClassName = []\n",
    "for f in predClassNum:\n",
    "     predClassName.append(inverse_target_map[f][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = classification_report(trueClassName, predClassName, output_dict=True)\n",
    "df = DataFrame(cl).transpose()\n",
    "df.to_csv (saveDir + r'classification_reports/valid.csv', index = True, header=True) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "cm = confusion_matrix(trueClassName, predClassName)\n",
    "df = DataFrame(cm)\n",
    "df.to_csv (saveDir + r'confusion_matrix/valid_total.csv', index = True, header=True) \n",
    "\n",
    "hm = heatmap(\n",
    " cm, xlabel='Predicted label',\n",
    " ylabel='True label', xticklabels=np.unique(trueClassName),\n",
    " yticklabels=np.unique(trueClassName), cmap=plt.cm.gray_r, fmt=\"%d\")\n",
    "plt.title(\"Total values \\n\")\n",
    "\n",
    "plt.colorbar(hm)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.savefig(saveDir + 'confusion_matrix/valid_total.svg', transparent = True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "cm = confusion_matrix(trueClassName, predClassName)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "df = DataFrame(cm)\n",
    "df.to_csv (saveDir + r'confusion_matrix/valid_normalised.csv', index = True, header=True) \n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "cm = heatmap(\n",
    " cm, xlabel='Predicted label',\n",
    " ylabel='True label', xticklabels=np.unique(trueClassName),\n",
    " yticklabels=np.unique(trueClassName), cmap=plt.cm.gray_r)\n",
    "plt.title(\"Normalised values\\n\")\n",
    "\n",
    "plt.colorbar(cm)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.savefig(saveDir + 'confusion_matrix/valid_normalised.svg', transparent = True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pred and prob to tsv\n",
    "\n",
    "df = DataFrame(list(zip(validImgId,trueClassName, predClassName,predProbabilityAll )), \n",
    "               columns =['ImgId', 'True', 'Predicted', 'Probability']) \n",
    "df = df.set_index('ImgId')\n",
    "\n",
    "df.to_csv (saveDir + r'predictions/valid.csv', index = True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueClassNum=[]\n",
    "for x in y_test:\n",
    "    ind = np.array(x).argmax()\n",
    "    y = ind\n",
    "    trueClassNum.append(y)\n",
    "    \n",
    "    \n",
    "trueClassName = []\n",
    "for f in trueClassNum:\n",
    "     trueClassName.append(inverse_target_map[f][:-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predMultilabelAll=[]\n",
    "predProbabilityAll = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for x in predTest:\n",
    "    \n",
    "    maxProb = x.max()\n",
    "    predProbabilityAll.append(maxProb)\n",
    "    \n",
    "    ind = x.argmax()\n",
    "    y = [0]*len(x)\n",
    "    y[ind]=1\n",
    "    predMultilabelAll.append(y)\n",
    "\n",
    "    counter +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to int\n",
    "predClassNum=[]\n",
    "for x in predMultilabelAll:\n",
    "    ind = np.array(x).argmax()\n",
    "    y = ind\n",
    "    predClassNum.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to name\n",
    "predClassName = []\n",
    "for f in predClassNum:\n",
    "     predClassName.append(inverse_target_map[f][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = classification_report(trueClassName, predClassName,output_dict=True)\n",
    "df = DataFrame(cl).transpose()\n",
    "df.to_csv (saveDir + r'classification_reports/test.csv', index = True, header=True) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "cm = confusion_matrix(trueClassName, predClassName)\n",
    "df = DataFrame(cm)\n",
    "df.to_csv (saveDir + r'confusion_matrix/test_total.csv', index = True, header=True) \n",
    "\n",
    "hm = heatmap(\n",
    " cm, xlabel='Predicted label',\n",
    " ylabel='True label', xticklabels=np.unique(trueClassName),\n",
    " yticklabels=np.unique(trueClassName), cmap=plt.cm.gray_r, fmt=\"%d\")\n",
    "plt.title(\"Total values \\n\")\n",
    "\n",
    "plt.colorbar(hm)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.savefig(saveDir + 'confusion_matrix/test_total.svg', transparent = True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "cm = confusion_matrix(trueClassName, predClassName)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "df = DataFrame(cm)\n",
    "df.to_csv (saveDir + r'confusion_matrix/test_normalised.csv', index = True, header=True) \n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "cm = heatmap(\n",
    " cm, xlabel='Predicted label',\n",
    " ylabel='True label', xticklabels=np.unique(trueClassName),\n",
    " yticklabels=np.unique(trueClassName), cmap=plt.cm.gray_r)\n",
    "plt.title(\"Normalised values\\n\")\n",
    "\n",
    "plt.colorbar(cm)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.savefig(saveDir + 'confusion_matrix/test_normalised.svg', transparent = True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pred and prob to tsv\n",
    "\n",
    "df = DataFrame(list(zip(validImgId,trueClassName, predClassName,predProbabilityAll )), \n",
    "               columns =['ImgId', 'True', 'Predicted', 'Probability']) \n",
    "df = df.set_index('ImgId')\n",
    "\n",
    "df.to_csv (saveDir + r'predictions/test.csv', index = True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName        = \"Modelname: \" + base_model.name\n",
    "trained          = \"Pre-Trained: \" + str(preTrained)\n",
    "overallRuntime   = \"Overall runtime: \" + str(sum.get_values()[0]) + \"s\"\n",
    "runtimePerEpoch  = \"Avg. runtime per Epoch: \" + str(avg.get_values()[0]) + \"s\"\n",
    "dsImg            = \"Dataset image: \" + imgDir\n",
    "dsTrain          = \"Dataset train: \" + trainTsv\n",
    "dsValid          = \"Dataset validation: \" + validTsv\n",
    "dsTest           = \"Dataset test: \" + testTsv\n",
    "testAcc          = \"Accuracy testset: \" + str(acc)\n",
    "testLoss         = \"Loss testset: \" + str(loss)\n",
    "numEpochs        = \"Num. Epochs: \" + str(len(history.epoch))\n",
    "earlyStop        = \"Early stop (0 if it didn't stop early): \" + str(earlyStopping_callback.stopped_epoch)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(saveDir + 'README.txt','w') as out:\n",
    "    out.write('{}\\n{}\\n\\n{}\\n{}\\n\\n{}\\n{}\\n{}\\n\\n{}\\n{}\\n{}\\n{}\\n{}\\n'.format(modelName,\n",
    "                                                                          trained,\n",
    "                                                                          testAcc,\n",
    "                                                                          testLoss,\n",
    "                                                                          numEpochs,\n",
    "                                                                          overallRuntime,\n",
    "                                                                          runtimePerEpoch,\n",
    "                                                                          dsImg,\n",
    "                                                                          dsTrain,\n",
    "                                                                          dsValid,\n",
    "                                                                          dsTest,\n",
    "                                                                          earlyStop\n",
    "                                                                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping_callback.stopped_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
